I"ı<h2 id="codex-invite">Codex Invite</h2>
<p>Got invited to try out Codex today! Looks pretty sweet. Can‚Äôt wait.
<img src="/assets/images/blog3/codexinvite.png" width="500" /></p>

<h2 id="testing-gpt-3">Testing GPT-3</h2>
<p>Today I was playing around with GPT-3(specifically davinci-instruct). I find that it‚Äôs plenty capable of understanding the context of a conversation and can detect when the context changes. This can be helpful for identifying parallel conversations.</p>

<p>It can also detect causal links between seemingly contradictory statements but it took a lot of refinement of asking the right questions in order to get the desired answers.</p>

<p>The goal is for GPT-3 to see the link between the two statements:
(1) Dogs are loyal.
(2) Dogs are dangerous.</p>

<p>The synthesis of these two statements requires introducing a third idea, which is that dogs want to protect their owners due to their loyalty; which causes them to be dangerous.</p>

<h3 id="fail-1">Fail #1:</h3>
<p><img src="/assets/images/blog3/firstfail.png" width="1000" /></p>

<p>GPT-3 seems to fail to recognize there‚Äôs a connection between dogs being loyal and dangerous. But it does rezognize that you can reconcile the two statements.</p>

<h3 id="fail-2">Fail #2:</h3>
<p><img src="/assets/images/blog3/fail2.png" width="1000" /></p>

<p>GPT-3 is giving contradicting answers to Fail #1. And then it contradicted itself again at the second question. At the last question, it attributed loyal to ‚Äúgood‚Äù and dangerous to ‚Äúbad‚Äù and said that a dog cannot inherently be both ‚Äúgood‚Äù and ‚Äúbad‚Äù. You can see that I got a little bit pissed in the middle there and started arguing with it a bit.</p>

<h3 id="bingo-1">Bingo #1</h3>
<p><img src="/assets/images/blog3/bingo1.png" width="1000" /></p>

<p>I tried again with the questions. It seems that GPT-3 doesn‚Äôt like absolute statements too much. But it acknowledged that dogs can be causally dangerous due to their loyalty and it synthesized a new idea, which is that dogs can protect thier owners.</p>

<p><img src="/assets/images/blog3/makinglink.png" width="500" /></p>

<p>Here‚Äôs a more concise way of asking that question. Also, I have noticed that a fresh prompt tends to give better anwers instead of appending new questions to the prompt and confusing the bot with irrelevant information.</p>

<h3 id="identifying-points-of-disagreement">Identifying points of disagreement</h3>

<p><img src="/assets/images/blog3/pointsofdisagreement.png" width="500" /></p>

<p>GPT-3 seems to think that axioms are de-facto true statements so no one should disagree on those. It also identifies the disagreement on value to possibly be their outlook on safety.</p>

<h3 id="identifying-strong-arguments">Identifying strong arguments</h3>

<p><img src="/assets/images/blog3/facts.png" width="500" /></p>

<p>Not too sure what metrics GPT-3 uses to rank these arguments. Not even too sure about the sources.</p>

<h3 id="cross-examing-arguments">Cross examing arguments</h3>

<p><img src="/assets/images/blog3/formattingneeded.png" width="250" /></p>

<p>I was trying to reproduce the results from before where GPT-3 could establish the causal link between two arguments. After failing a couple of times, I realized GPT-3 was identifying the correct arguments I was pointing to. So I tried a couple of different ways of formatting. In the future, I will probably need to assign a code to every statement.</p>

<p><img src="/assets/images/blog3/betterformatting.png" width="500" /></p>

<p>This formatting is better.</p>
:ET